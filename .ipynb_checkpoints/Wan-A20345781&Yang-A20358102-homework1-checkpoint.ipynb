{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team member: Chao Wan(A20345781), Dalin Yang(A20358102)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import library and read the data from file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import scipy as sp  \n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve  \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from collections import Counter\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.mlab as mlab    \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open(\"communities-crime-clean.csv\", \"r\")\n",
    "\n",
    "data = []\n",
    "crimeRate = []\n",
    "highCrime = []\n",
    "features = f.readline().strip().split(\",\")\n",
    "line = f.readline()\n",
    "while line:\n",
    "    tokens = line.strip().split(\",\")\n",
    "    tuple = []\n",
    "    for attr in tokens[3:-1]:\n",
    "        tuple.append(float(attr))\n",
    "    data.append(tuple)\n",
    "    crimeRate.append(float(tokens[-1]))\n",
    "    if(float(tokens[-1]) > 0.1):\n",
    "        highCrime.append(True)\n",
    "    else:\n",
    "        highCrime.append(False)\n",
    "    line = f.readline()\n",
    "x = np.array(data)\n",
    "y = np.array(highCrime)\n",
    "y2= np.array(crimeRate)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Postive Percentage & Nagetive Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62719518314099343"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PositivePercent = np.sum(y==True)/len(y)\n",
    "PositivePercent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37280481685900652"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NagetivePercent = np.sum(y==False)/len(y)\n",
    "NagetivePercent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### b. Use DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier()    \n",
    "clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i. Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   LowCrime       1.00      1.00      1.00       743\n",
      "  HighCrime       1.00      1.00      1.00      1250\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1993\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y, y)\n",
    "print(\"Accuracy:\", accuracy, \"\\n\")\n",
    "answer = clf.predict_proba(x)[:,1]  \n",
    "print(classification_report(y, answer, target_names = ['LowCrime', 'HighCrime'])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii.Mean Features:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean featrues are PctKids2Par, racePctWhite and racePctHisp. \n",
    "Because when we tracing the data, we will find the PctKidsPar or racePctWhite or racePctHisp with higher number will have lower crime rate, and the vice versa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PctKids2Par', 0.3597251889048339),\n",
       " ('racePctWhite', 0.090533571999860493),\n",
       " ('racePctHisp', 0.050532236222209419),\n",
       " ('PctLess9thGrade', 0.022780774918367497),\n",
       " ('PctEmplManu', 0.017035270197975357),\n",
       " ('MedRent', 0.015301814701351533),\n",
       " ('PctImmigRec10', 0.014596466282100392),\n",
       " ('PctHousOwnOcc', 0.013685604733908239),\n",
       " ('PctSpeakEnglOnly', 0.012476414096854615),\n",
       " ('PctSameState85', 0.012219169785146998)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier()    \n",
    "clf.fit(x, y)\n",
    "nvs = zip(features[3:-1], clf.feature_importances_)\n",
    "nvDict = dict((name,value) for name,value in nvs)\n",
    "sortFeature = sorted(nvDict.items(), key=lambda item:-item[1])\n",
    "sortFeature[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Apply cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i. Accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.75        0.795       0.745       0.74371859  0.67336683  0.64824121\n",
      "  0.72361809  0.68844221  0.77889447  0.73366834]\n",
      "The average of accuracy: 0.727994974874\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(clf, x, y, scoring = \"accuracy\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of accuracy:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.77697842  0.83206107  0.76335878  0.78518519  0.77884615  0.73584906\n",
      "  0.77777778  0.86021505  0.76223776  0.81896552]\n",
      "The average of precision: 0.789147477125\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(clf, x, y, scoring = \"precision\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of precision:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.856  0.896  0.76   0.872  0.608  0.664  0.8    0.656  0.896  0.744]\n",
      "The average of recall: 0.7752\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(clf, x, y, scoring = \"recall\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of recall:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. The Reason of Difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the decision tree is only based on the training data, it will got mistake when applying to the test data which should be different with trainning data. Therefore, the result will not be 100% match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Howerver, the previous decision tree is trained on the entire dataset, and also test on these data, the result should obvious be the 100% match. It's kind of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Linear Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Use GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i.Accuracy, precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.775       0.8         0.825       0.79899497  0.70351759  0.65326633\n",
      "  0.81407035  0.73366834  0.71356784  0.79899497]\n",
      "The average of accuracy: 0.761608040201\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "answer = cross_val_score(clf, x, y, scoring = \"accuracy\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of accuracy:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.86363636  0.92929293  0.95        0.92079208  0.94594595  0.86842105\n",
      "  0.92307692  1.          0.77868852  0.93814433]\n",
      "The average of precision: 0.911799814828\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(clf, x, y, scoring = \"precision\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of precision:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.76   0.736  0.76   0.744  0.56   0.528  0.768  0.576  0.76   0.728]\n",
      "The average of recall: 0.692\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(clf, x, y, scoring = \"recall\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of recall:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### ii. Most Predictive Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PctKids2Par', 5.0013102290317129),\n",
       " ('FemalePctDiv', 4.7568859628347688),\n",
       " ('PctFam2Par', 4.5939880055148983),\n",
       " ('pctWInvInc', 4.3949908462647498),\n",
       " ('TotalPctDiv', 4.3859860760484883),\n",
       " ('PctTeen2Par', 3.9993536543892376),\n",
       " ('MalePctDivorce', 3.9507314134882674),\n",
       " ('PctYoungKids2Par', 3.6483010761779187),\n",
       " ('PctIlleg', 3.4698885121965644),\n",
       " ('racePctWhite', 3.4432283131853589)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "answer = clf.fit(x, y)\n",
    "diff = abs(answer.theta_[0] - answer.theta_[1])/(answer.sigma_[0] + answer.sigma_[1])\n",
    "nvs = zip(features[3:-1], diff)\n",
    "nvDict = dict((name,value) for name,value in nvs)\n",
    "sortFeature = sorted(nvDict.items(), key=lambda item:-item[1])\n",
    "sortFeature[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It make sence. If the feature has higher rank, it means that the difference of means of this feature bewteen two classes is relative big or the varience is raletive small. Therefore, this kind feature has a clearer classification between two classes since it has a relative clear gap, and so it can be used to predict output (classes). Additionally, in the file, these features has the obviously seperated output (classes) along the ascendent feature values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### iii. Compare to decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GaussianNB has much better precision but worse recall, and the precision is little better. This shows that the GaussianNB may not find most positive data, but the data has a high possibility to be positive when GaussianNB predict it as positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For key features, few features both have similar ranks and majority features got different ranks in GaussianNB, for example, the racePctWhite. This is because although they has a better thesthold to seperate the two classes, the means of these two classes may be close or the data in two classes spread too widely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i. 10-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.79        0.865       0.84        0.80904523  0.69346734  0.69346734\n",
      "  0.81407035  0.8241206   0.81909548  0.81407035]\n",
      "The average of accuracy: 0.796233668342\n"
     ]
    }
   ],
   "source": [
    "clf = LinearSVC()\n",
    "answer = cross_val_score(clf, x, y, scoring = \"accuracy\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of accuracy:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.76774194  0.84507042  0.82517483  0.85950413  0.87209302  0.7962963\n",
      "  0.84920635  0.95918367  0.80689655  0.87288136]\n",
      "The average of precision: 0.845404856531\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(clf, x, y, scoring = \"precision\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of precision:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.952  0.96   0.944  0.832  0.6    0.688  0.856  0.752  0.936  0.824]\n",
      "The average of recall: 0.8344\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(clf, x, y, scoring = \"recall\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of recall:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. 10 most predict feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we just see the signle features, some of them do not make sence. But if we caculate them with weight together, it can seperate the two classes clearly, since this method take account all the features to predict highCrime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pctWInvInc', 1.8884872753574939),\n",
       " ('PersPerOccupHous', 1.7551236098625982),\n",
       " ('racePctWhite', 1.5002170472255181),\n",
       " ('PctKids2Par', 1.1903278739440728),\n",
       " ('RentHighQ', 1.0668837880418409),\n",
       " ('MalePctDivorce', 1.0656961744329736),\n",
       " ('NumUnderPov', 1.0515482755155021),\n",
       " ('NumStreet', 1.019143992337431),\n",
       " ('PctOccupMgmtProf', 1.0146749260525534),\n",
       " ('population', 1.0023012880707545)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearSVC()\n",
    "answer = clf.fit(x,y)\n",
    "nvs = zip(features[3:-1], abs(answer.coef_[0]))\n",
    "nvDict = dict((name,value) for name,value in nvs)\n",
    "sortFeature = sorted(nvDict.items(), key=lambda item:-item[1])\n",
    "sortFeature[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### iii. Compare to decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the CV results become better, since the Linear SVC consider the relationship between features while decision tree does not care it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For key featrues, also there is a big difference between the results of LinearSVC and Decision tree. The reason is that LinearSVC is trying to find a hyperplane to classify and take all the features into account, so the weight of one feature is affects by the distribution of other featrues. However, the decision tree just consider one featrue to find the most important feature in one step.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Use LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i. 10-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02983448,  0.02048526,  0.02735939,  0.02320408,  0.01944074,\n",
       "        0.01262621,  0.01844842,  0.01222962,  0.02183042,  0.01548108])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_clf = LinearRegression()\n",
    "answer = cross_val_score(LR_clf, x, y2, scoring = \"neg_mean_squared_error\", cv = 10)\n",
    "-answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. MSE on entrie set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0165167748803\n"
     ]
    }
   ],
   "source": [
    "answer = LR_clf.fit(x, y2)\n",
    "y2_predict = LR_clf.predict(x)\n",
    "print(mean_squared_error(y2, y2_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii. Most Precitive Featrues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For high crime rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PersPerOccupHous', 0.6350881164986133),\n",
       " ('PctHousOwnOcc', 0.56813320988653082),\n",
       " ('MalePctDivorce', 0.45851704864166098),\n",
       " ('PctRecImmig8', 0.43251055765291008),\n",
       " ('MedRent', 0.37272779771138975),\n",
       " ('medFamInc', 0.28797887494607072),\n",
       " ('PctEmploy', 0.24847431608470519),\n",
       " ('MalePctNevMarr', 0.22672791284180535),\n",
       " ('PctPersDenseHous', 0.21435256414197748),\n",
       " ('OwnOccMedVal', 0.21287586365359706)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nvs = zip(features[3:-1], answer.coef_)\n",
    "nvDict = dict((name,value) for name,value in nvs)\n",
    "sortFeature = sorted(nvDict.items(), key=lambda item:-item[1])\n",
    "sortFeature[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For low crime rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PctPersOwnOccup', -0.67569447880286471),\n",
       " ('TotalPctDiv', -0.56192431441465263),\n",
       " ('whitePerCap', -0.3510157744407798),\n",
       " ('PctKids2Par', -0.32265127649627445),\n",
       " ('OwnOccLowQuart', -0.30817021919318288),\n",
       " ('numbUrban', -0.2964425431775653),\n",
       " ('PersPerRentOccHous', -0.25457166271646947),\n",
       " ('RentLowQ', -0.23475151630251967),\n",
       " ('agePct12t29', -0.22921783699885442),\n",
       " ('PctRecImmig5', -0.2182210073546518)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_sortFeature = sorted(nvDict.items(), key=lambda item:item[1])\n",
    "neg_sortFeature[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### b. Use Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i. MSE under 10-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0295138 ,  0.01972075,  0.02795035,  0.02311508,  0.01872138,\n",
       "        0.0120445 ,  0.01780565,  0.01212225,  0.02191791,  0.01503854])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ri_clf = Ridge()\n",
    "answer = cross_val_score(Ri_clf, x, y2, scoring = \"neg_mean_squared_error\", cv = 10)\n",
    "-answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### ii. MSE on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0167635291552\n"
     ]
    }
   ],
   "source": [
    "Ri_clf = Ridge()\n",
    "answer = Ri_clf.fit(x, y2)\n",
    "y2_predict = Ri_clf.predict(x)\n",
    "print(mean_squared_error(y2, y2_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### iii. best alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "Rcv_clf = RidgeCV(alphas = (10, 1, 0.1, 0.01, 0.001), cv =10)\n",
    "answer = Rcv_clf.fit(x, y2)\n",
    "print(Rcv_clf.alpha_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### iv. About Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The ridge get little better result on 10-fold CV, but get little worse result on the training set, which means ridge takes less overfitting since it can predict more precisely on other test data while predict worese on training set itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### c. Use Polynomial Features to do quadratic polynomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i. MSE of 10-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.15479511,  0.14987831,  0.19852503,  0.10211292,  0.07857856,\n",
       "        0.14101072,  0.09207106,  0.07377483,  0.16920729,  0.13902769])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=2)\n",
    "x_ = poly.fit_transform(x)\n",
    "LR_clf = LinearRegression()\n",
    "answer = cross_val_score(LR_clf, x_, y2, scoring = \"neg_mean_squared_error\", cv = 10)\n",
    "-answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. MSE on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.69580219538e-28\n"
     ]
    }
   ],
   "source": [
    "LR_clf.fit(x_, y2)\n",
    "print(mean_squared_error(y2, LR_clf.predict(x_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii. Whether better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Since the quadratic polynomial regression get higher MSE than that in linear regression in 10-fold CV, this quadratic polynomial regression get worse match than linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Moreover, on the training set, the quadratic polynomial regression getting better error value should be the result of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dirty Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the data from full csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f2 = open(\"communities-crime-full.csv\", \"r\")\n",
    "\n",
    "data2 = []\n",
    "crimeRate2 = []\n",
    "highCrime2 = []\n",
    "features2 = f2.readline().strip().split(\",\")\n",
    "line = f2.readline()\n",
    "while line:\n",
    "    line = line.replace(\",?\",\",nan\")\n",
    "    tokens = line.strip().split(\",\")\n",
    "    data2.append(tokens[5:-1])\n",
    "    crimeRate2.append(float(tokens[-1]))\n",
    "    if(float(tokens[-1]) > 0.1):\n",
    "        highCrime2.append(True)\n",
    "    else:\n",
    "        highCrime2.append(False)\n",
    "    line = f2.readline()\n",
    "x_2 = np.array(data2)\n",
    "y_2 = np.array(highCrime2)\n",
    "y_2_2= np.array(crimeRate2)\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imp = Imputer(missing_values=\"NaN\", strategy='most_frequent', axis=0)  \n",
    "x_imp = imp.fit_transform(x_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. CV results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.80597015  0.745       0.735       0.72864322  0.72864322  0.73366834\n",
      "  0.83417085  0.77386935  0.73869347  0.73366834]\n",
      "The average of accuracy: 0.755732693317\n"
     ]
    }
   ],
   "source": [
    "DT_clf = tree.DecisionTreeClassifier()\n",
    "answer = cross_val_score(DT_clf, x_imp, y_2, scoring = \"accuracy\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of accuracy:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.83870968  0.808       0.79661017  0.80152672  0.76984127  0.808\n",
      "  0.86290323  0.84482759  0.79661017  0.78125   ]\n",
      "The average of precision: 0.810827881581\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(DT_clf, x_imp, y_2, scoring = \"precision\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of precision:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.80952381  0.832       0.784       0.824       0.76        0.752       0.832\n",
      "  0.808       0.752       0.792     ]\n",
      "The average of recall: 0.794552380952\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(DT_clf, x_imp, y_2, scoring = \"recall\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of recall:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the CV results becomes better after adding the dirty data. Therefore, the feature with missing values can also provide the trace, which can contribute to the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Teamworkï¼š "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. (1) Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.775       0.85        0.83        0.8040201   0.67336683  0.68844221\n",
      "  0.83417085  0.75879397  0.8040201   0.80904523]\n",
      "The average of accuracy: 0.782685929648\n"
     ]
    }
   ],
   "source": [
    "RF_clf = RandomForestClassifier()\n",
    "answer = cross_val_score(RF_clf, x, y, scoring = \"accuracy\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of accuracy:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.78321678  0.8828125   0.88709677  0.88235294  0.88043478  0.84848485\n",
      "  0.8359375   0.94680851  0.83206107  0.83898305]\n",
      "The average of presion: 0.861818875987\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(RF_clf, x, y, scoring = \"precision\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of presion:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.936  0.936  0.92   0.768  0.656  0.648  0.848  0.704  0.904  0.8  ]\n",
      "The average of recall: 0.812\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(RF_clf, x, y, scoring = \"recall\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of recall:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PctKids2Par', 0.076824674000833287),\n",
       " ('PctIlleg', 0.074654892720768015),\n",
       " ('racePctWhite', 0.056145440464856887),\n",
       " ('TotalPctDiv', 0.041481966405490414),\n",
       " ('PctPersDenseHous', 0.040571605932169609),\n",
       " ('racepctblack', 0.036009739412114203),\n",
       " ('NumIlleg', 0.033192552779043476),\n",
       " ('pctWPubAsst', 0.030247875037522153),\n",
       " ('MalePctDivorce', 0.025354629420964187),\n",
       " ('pctWInvInc', 0.019293913825466358)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_clf.fit(x, y)\n",
    "nvs = zip(features[3:-1], RF_clf.feature_importances_)\n",
    "nvDict = dict((name,value) for name,value in nvs)\n",
    "sortFeature = sorted(nvDict.items(), key=lambda item:-item[1])\n",
    "sortFeature[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dirty data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.84079602  0.83        0.855       0.80904523  0.78894472  0.8241206\n",
      "  0.81407035  0.79396985  0.83417085  0.79899497]\n",
      "The average of accuracy: 0.818911260282\n"
     ]
    }
   ],
   "source": [
    "RF_clf = RandomForestClassifier()\n",
    "answer = cross_val_score(RF_clf, x_imp, y_2, scoring = \"accuracy\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of accuracy:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.89344262  0.84677419  0.84920635  0.83333333  0.89915966  0.86956522\n",
      "  0.8907563   0.91891892  0.83870968  0.86178862]\n",
      "The average of presion: 0.870165489704\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(RF_clf, x_imp, y_2, scoring = \"precision\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of presion:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.84920635  0.896       0.848       0.848       0.824       0.808       0.8\n",
      "  0.76        0.88        0.816     ]\n",
      "The average of recall: 0.832920634921\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(RF_clf, x_imp, y_2, scoring = \"recall\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of recall:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PctPersDenseHous', 0.072821299288081259),\n",
       " ('PctKids2Par', 0.064593937780324767),\n",
       " ('NumIlleg', 0.055860359869965091),\n",
       " ('pctWPubAsst', 0.047493632627543518),\n",
       " ('FemalePctDiv', 0.046138502050214643),\n",
       " ('MalePctDivorce', 0.04309545725618473),\n",
       " ('PctIlleg', 0.038893994558554225),\n",
       " ('racePctWhite', 0.028212163050568072),\n",
       " ('PctHousLess3BR', 0.025966555330106632),\n",
       " ('PctNotHSGrad', 0.018593830982340638)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_clf.fit(x_imp, y_2)\n",
    "nvs = zip(features[3:-1], RF_clf.feature_importances_)\n",
    "nvDict = dict((name,value) for name,value in nvs)\n",
    "sortFeature = sorted(nvDict.items(), key=lambda item:-item[1])\n",
    "sortFeature[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. (2) GradientBoosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.79        0.89        0.88        0.81407035  0.69346734  0.72864322\n",
      "  0.78894472  0.81407035  0.7638191   0.82914573]\n",
      "The average of accuracy: 0.799216080402\n"
     ]
    }
   ],
   "source": [
    "B_clf = GradientBoostingClassifier()\n",
    "answer = cross_val_score(B_clf, x, y, scoring = \"accuracy\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of accuracy:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.77124183  0.89230769  0.87407407  0.85365854  0.86363636  0.85858586\n",
      "  0.81679389  0.94        0.75163399  0.8699187 ]\n",
      "The average of precision: 0.84918509345\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(B_clf, x, y, scoring = \"precision\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of precision:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.944  0.92   0.944  0.832  0.6    0.68   0.856  0.752  0.92   0.856]\n",
      "The average of recall: 0.8304\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(B_clf, x, y, scoring = \"recall\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of recall:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Key Featrues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PctKids2Par', 0.080401108416970929),\n",
       " ('racePctWhite', 0.060479605405120103),\n",
       " ('pctWInvInc', 0.027985251341367326),\n",
       " ('FemalePctDiv', 0.027479502008895925),\n",
       " ('PctIlleg', 0.024581419243101442),\n",
       " ('NumIlleg', 0.022599223727140544),\n",
       " ('PctEmplManu', 0.021020623390471095),\n",
       " ('PctWOFullPlumb', 0.02064146481338585),\n",
       " ('PctBornSameState', 0.020507724005285222),\n",
       " ('blackPerCap', 0.020210996418640548)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_clf.fit(x, y)\n",
    "nvs = zip(features[3:-1], B_clf.feature_importances_)\n",
    "nvDict = dict((name,value) for name,value in nvs)\n",
    "sortFeature = sorted(nvDict.items(), key=lambda item:-item[1])\n",
    "sortFeature[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dirty data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.85074627  0.83        0.85        0.81407035  0.83417085  0.82914573\n",
      "  0.85427136  0.83919598  0.82914573  0.8241206 ]\n",
      "The average of accuracy: 0.835486687167\n"
     ]
    }
   ],
   "source": [
    "B_clf = GradientBoostingClassifier()\n",
    "answer = cross_val_score(B_clf, x_imp, y_2, scoring = \"accuracy\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of accuracy:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.88709677  0.85826772  0.8671875   0.83969466  0.8907563   0.864\n",
      "  0.90677966  0.8974359   0.87096774  0.8515625 ]\n",
      "The average of precision: 0.873374875013\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(B_clf, x_imp, y_2, scoring = \"precision\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of precision:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.87301587  0.864       0.896       0.872       0.848       0.864       0.856\n",
      "  0.848       0.864       0.872     ]\n",
      "The average of recall: 0.865701587302\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(B_clf, x_imp, y_2, scoring = \"recall\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of recall:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Key Featrues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PctKids2Par', 0.081483172806808127),\n",
       " ('racePctWhite', 0.052435582657868317),\n",
       " ('FemalePctDiv', 0.032857604141464838),\n",
       " ('PctImmigRec10', 0.024810590334708896),\n",
       " ('PctBornSameState', 0.023418099001997431),\n",
       " ('NumIlleg', 0.022179261853530217),\n",
       " ('pctWInvInc', 0.020899450840109957),\n",
       " ('PctImmigRec5', 0.020874866909534592),\n",
       " ('PctVacMore6Mos', 0.020319104558007593),\n",
       " ('HousVacant', 0.019388409742180999)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_clf.fit(x_imp, y_2)\n",
    "nvs = zip(features[3:-1], B_clf.feature_importances_)\n",
    "nvDict = dict((name,value) for name,value in nvs)\n",
    "sortFeature = sorted(nvDict.items(), key=lambda item:-item[1])\n",
    "sortFeature[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. Which method give best result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we use the dirty data, we can know from the result that Gradient Boosting get the best accuracy, recall and Precision.\n",
    "When we use the clean data, the Gradient Boosting get the best accuracy. \n",
    "It shows that the combination of base learners can really improve the result a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sepcifically, the GaussianNB get the best precision ,and the LinearSVC get best recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii. Key features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The featrue \"PctKids2Par\" seen to be the most consistency predictive of high crime rate. This conclusion should has high reliability since it always have a high weight among these methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 6. Extra Work: (1) ada Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.8         0.825       0.865       0.79396985  0.69849246  0.69849246\n",
      "  0.80904523  0.77386935  0.76884422  0.79396985]\n",
      "The average of accuracy: 0.782668341709\n"
     ]
    }
   ],
   "source": [
    "B_clf = AdaBoostClassifier()\n",
    "answer = cross_val_score(B_clf, x, y, scoring = \"accuracy\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of accuracy:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.77419355  0.82608696  0.88888889  0.828125    0.84946237  0.81553398\n",
      "  0.80851064  0.96511628  0.77622378  0.83870968]\n",
      "The average of precision: 0.837085111098\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(B_clf, x, y, scoring = \"precision\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of precision:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.96   0.912  0.896  0.848  0.632  0.672  0.912  0.664  0.888  0.832]\n",
      "The average of recall: 0.8216\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(B_clf, x, y, scoring = \"recall\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of recall:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('racePctWhite', 0.12),\n",
       " ('PctKids2Par', 0.10000000000000001),\n",
       " ('TotalPctDiv', 0.059999999999999998),\n",
       " ('PctHousNoPhone', 0.059999999999999998),\n",
       " ('agePct12t21', 0.040000000000000001),\n",
       " ('pctWInvInc', 0.040000000000000001),\n",
       " ('PctTeen2Par', 0.040000000000000001),\n",
       " ('LandArea', 0.040000000000000001),\n",
       " ('population', 0.02),\n",
       " ('householdsize', 0.02)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_clf.fit(x, y)\n",
    "nvs = zip(features[3:-1], B_clf.feature_importances_)\n",
    "nvDict = dict((name,value) for name,value in nvs)\n",
    "sortFeature = sorted(nvDict.items(), key=lambda item:-item[1])\n",
    "sortFeature[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dirty data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.84079602  0.85        0.775       0.81407035  0.8040201   0.81407035\n",
      "  0.84924623  0.82914573  0.79396985  0.81909548]\n",
      "The average of accuracy: 0.818941411035\n"
     ]
    }
   ],
   "source": [
    "B_clf = AdaBoostClassifier()\n",
    "answer = cross_val_score(B_clf, x_imp, y_2, scoring = \"accuracy\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of accuracy:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.86153846  0.88        0.82258065  0.81884058  0.84677419  0.86065574\n",
      "  0.88617886  0.88888889  0.83870968  0.83969466]\n",
      "The average of precision: 0.854386170225\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(B_clf, x_imp, y_2, scoring = \"precision\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of precision:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.88888889  0.88        0.816       0.904       0.84        0.84        0.872\n",
      "  0.832       0.832       0.88      ]\n",
      "The average of recall: 0.858488888889\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(B_clf, x_imp, y_2, scoring = \"recall\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of recall:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('racePctWhite', 0.10000000000000001),\n",
       " ('PctKids2Par', 0.10000000000000001),\n",
       " ('pctWInvInc', 0.059999999999999998),\n",
       " ('TotalPctDiv', 0.059999999999999998),\n",
       " ('agePct12t21', 0.040000000000000001),\n",
       " ('perCapInc', 0.040000000000000001),\n",
       " ('PctTeen2Par', 0.040000000000000001),\n",
       " ('population', 0.02),\n",
       " ('householdsize', 0.02),\n",
       " ('racepctblack', 0.02)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_clf.fit(x_imp, y_2)\n",
    "nvs = zip(features[3:-1], B_clf.feature_importances_)\n",
    "nvDict = dict((name,value) for name,value in nvs)\n",
    "sortFeature = sorted(nvDict.items(), key=lambda item:-item[1])\n",
    "sortFeature[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.Extra work: (2) SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.785       0.89        0.9         0.81407035  0.60301508  0.56281407\n",
      "  0.8241206   0.85929648  0.79396985  0.79396985]\n",
      "The average of accuracy: 0.782625628141\n"
     ]
    }
   ],
   "source": [
    "SGD_clf = SGDClassifier()\n",
    "answer = cross_val_score(SGD_clf, x, y, scoring = \"accuracy\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of accuracy:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.82539683  0.73652695  0.95098039  0.98780488  0.89156627  0.83838384\n",
      "  0.79861111  0.79054054  0.64921466  0.97560976]\n",
      "The average of precision: 0.844463521259\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(SGD_clf, x, y, scoring = \"precision\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of precision:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.88   0.88   0.936  0.84   0.984  0.648  0.976  0.496  0.984  0.608]\n",
      "The average of recall: 0.8232\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(SGD_clf, x, y, scoring = \"recall\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of recall:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('racepctblack', 18.515140459686272),\n",
       " ('PctIlleg', 10.525355709595019),\n",
       " ('racePctHisp', 10.142283838015292),\n",
       " ('MalePctDivorce', 9.2666909886902182),\n",
       " ('OtherPerCap', 9.2484494709959915),\n",
       " ('TotalPctDiv', 9.2028456767602904),\n",
       " ('FemalePctDiv', 8.2269244801166952),\n",
       " ('PctPersDenseHous', 8.2178037212695774),\n",
       " ('LemasPctOfficDrugUn', 7.415176942721625),\n",
       " ('MedRentPctHousInc', 7.3148485954031219)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGD_clf.fit(x,y)\n",
    "nvs = zip(features[3:-1], SGD_clf.coef_[0])\n",
    "nvDict = dict((name,value) for name,value in nvs)\n",
    "sortFeature = sorted(nvDict.items(), key=lambda item:-item[1])\n",
    "sortFeature[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('racePctWhite', -18.934695366654498),\n",
       " ('pctWInvInc', -18.515140459686219),\n",
       " ('PctKids2Par', -11.255016417365889),\n",
       " ('PctFam2Par', -8.3546151039766254),\n",
       " ('PctHousOccup', -8.0353885443268585),\n",
       " ('MedOwnCostPctIncNoMtg', -7.3330901130974278),\n",
       " ('RentLowQ', -6.2112367748996817),\n",
       " ('PctWOFullPlumb', -6.2021160160525648),\n",
       " ('PctYoungKids2Par', -6.0926669098868711),\n",
       " ('PctBSorMore', -5.1623495074790506)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_sortFeature = sorted(nvDict.items(), key=lambda item:item[1])\n",
    "neg_sortFeature[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dirty data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.82089552  0.805       0.75        0.83919598  0.7839196   0.70351759\n",
      "  0.69346734  0.8241206   0.82914573  0.81407035]\n",
      "The average of accuracy: 0.786333270832\n"
     ]
    }
   ],
   "source": [
    "SGD_clf = SGDClassifier()\n",
    "answer = cross_val_score(SGD_clf, x_imp, y_2, scoring = \"accuracy\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of accuracy:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.72352941  0.7852349   0.79020979  0.67934783  0.832       0.93269231\n",
      "  0.74390244  0.94230769  0.98765432  0.87272727]\n",
      "The average of precision: 0.828960596013\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(SGD_clf, x_imp, y_2, scoring = \"precision\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of precision:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.65079365  1.          0.968       0.76        0.584       0.88        0.672\n",
      "  0.4         0.976       0.824     ]\n",
      "The average of recall: 0.771479365079\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(SGD_clf, x_imp, y_2, scoring = \"recall\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of recall:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('racepctblack', 20.594402406782777),\n",
       " ('PctIlleg', 11.477801075758917),\n",
       " ('MalePctDivorce', 10.274409700063803),\n",
       " ('racePctHisp', 8.4966724405141285),\n",
       " ('TotalPctDiv', 8.4510894338590319),\n",
       " ('PctPersDenseHous', 7.1291822408606009),\n",
       " ('PctImmigRec10', 6.3269213237305051),\n",
       " ('FemalePctDiv', 6.1445892971100111),\n",
       " ('OtherPerCap', 6.135472695779014),\n",
       " ('HousVacant', 5.7434588385449894)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGD_clf.fit(x_imp,y_2)\n",
    "nvs = zip(features[3:-1], SGD_clf.coef_[0])\n",
    "nvDict = dict((name,value) for name,value in nvs)\n",
    "sortFeature = sorted(nvDict.items(), key=lambda item:-item[1])\n",
    "sortFeature[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('racePctWhite', -20.667335217430931),\n",
       " ('pctWInvInc', -19.190445801805044),\n",
       " ('PctKids2Par', -11.669249703710429),\n",
       " ('PctWOFullPlumb', -8.3872732245419392),\n",
       " ('RentLowQ', -8.1411249886042487),\n",
       " ('PctFam2Par', -8.0408423739629828),\n",
       " ('PctHousOccup', -7.2568146594949239),\n",
       " ('HispPerCap', -5.9349074664964885),\n",
       " ('PctBSorMore', -5.907557662503403),\n",
       " ('PctOccupManu', -5.0870635427112987)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_sortFeature = sorted(nvDict.items(), key=lambda item:item[1])\n",
    "neg_sortFeature[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### i. Which method give best result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The situation is similar with that in team work, but this time the SGD get best Precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### ii. Best Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The featrue \"PctKids2Par\" seen to be the most consistency predictive of high crime rate. This conclusion should has high reliability since it always have a high weight among these methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 6.Extra work: team work for three people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### ii. The most useful threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.13872487],\n",
       "       [ 0.63204489]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crimeT = []\n",
    "for attr in crimeRate:\n",
    "    tuple = []\n",
    "    tuple.append(attr)\n",
    "    crimeT.append(tuple) \n",
    "K_clf = KMeans(n_clusters=2)\n",
    "K_clf.fit(crimeT)\n",
    "K_clf.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.385413529892\n"
     ]
    }
   ],
   "source": [
    "threshold = abs(K_clf.cluster_centers_[0][0] + K_clf.cluster_centers_[1][0])/2\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The threshold can be 0.3854 for clean data. It is useful because it divides the crime rates into two relative compacted and different clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.13878217],\n",
       "       [ 0.63204489]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crimeT2 = []\n",
    "for attr in crimeRate2:\n",
    "    tuple = []\n",
    "    tuple.append(attr)\n",
    "    crimeT2.append(tuple) \n",
    "K_clf = KMeans(n_clusters=2)\n",
    "K_clf.fit(crimeT2)\n",
    "K_clf.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.385413529892\n"
     ]
    }
   ],
   "source": [
    "threshold2 = abs(K_clf.cluster_centers_[0][0] + K_clf.cluster_centers_[1][0])/2\n",
    "print(threshold2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For dirty data, the useful threshold can be 0.3854."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### iii. the new CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caculate the new lable by the new threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newCrime = []\n",
    "for attr in crimeRate:\n",
    "    if(attr > threshold):\n",
    "        newCrime.append(True)\n",
    "    else:\n",
    "        newCrime.append(False)\n",
    "y_new = np.array(newCrime)\n",
    "\n",
    "newCrime_full = []\n",
    "for attr in crimeRate2:\n",
    "    if(attr > threshold2):\n",
    "        newCrime_full.append(True)\n",
    "    else:\n",
    "        newCrime_full.append(False)\n",
    "y_2_new = np.array(newCrime_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CV results for clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.76119403  0.835       0.69849246  0.81407035  0.84422111  0.77889447\n",
      "  0.85427136  0.85929648  0.64824121  0.77386935]\n",
      "The average of accuracy: 0.786755081377\n"
     ]
    }
   ],
   "source": [
    "Tree_clf = tree.DecisionTreeClassifier()\n",
    "answer = cross_val_score(Tree_clf, x, y_new, scoring = \"accuracy\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of accuracy:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.42        0.6         0.34920635  0.53125     0.55813953  0.44444444\n",
      "  0.65116279  0.61111111  0.32098765  0.38461538]\n",
      "The average of precision: 0.487091726928\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(Tree_clf, x, y_new, scoring = \"precision\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of precision:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.63414634  0.55        0.525       0.5         0.5         0.575       0.65\n",
      "  0.65        0.65        0.425     ]\n",
      "The average of recall: 0.565914634146\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(Tree_clf, x, y_new, scoring = \"recall\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of recall:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CV results for Dirty data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.8159204   0.8         0.81        0.84924623  0.83919598  0.79899497\n",
      "  0.83417085  0.79899497  0.85929648  0.84924623]\n",
      "The average of accuracy: 0.825506612665\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(Tree_clf, x_imp, y_2_new, scoring = \"accuracy\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of accuracy:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.52631579  0.43181818  0.5         0.55813953  0.66666667  0.5\n",
      "  0.61363636  0.47727273  0.64285714  0.64864865]\n",
      "The average of precision: 0.556535505526\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(Tree_clf, x_imp, y_2_new, scoring = \"precision\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of precision:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.48780488  0.5         0.7         0.725       0.525       0.55        0.625\n",
      "  0.475       0.725       0.6       ]\n",
      "The average of recall: 0.591280487805\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(Tree_clf, x_imp, y_2_new, scoring = \"recall\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of recall:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CV results for clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.82587065  0.89        0.78894472  0.89949749  0.87437186  0.84924623\n",
      "  0.89949749  0.89949749  0.72864322  0.83417085]\n",
      "The average of accuracy: 0.84897399935\n"
     ]
    }
   ],
   "source": [
    "B_clf = GradientBoostingClassifier()\n",
    "answer = cross_val_score(B_clf, x, y_new, scoring = \"accuracy\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of accuracy:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.575       0.76470588  0.47727273  0.77777778  0.72727273  0.65625     0.8\n",
      "  0.83333333  0.4         0.6       ]\n",
      "The average of precision: 0.661161244801\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(B_clf, x, y_new, scoring = \"precision\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of precision:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.56097561  0.625       0.525       0.7         0.6         0.525       0.7\n",
      "  0.625       0.7         0.45      ]\n",
      "The average of recall: 0.601097560976\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(B_clf, x, y_new, scoring = \"recall\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of recall:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CV results for dirty data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.88557214  0.89        0.87        0.88944724  0.89949749  0.90954774\n",
      "  0.90954774  0.87939698  0.90954774  0.87437186]\n",
      "The average of accuracy: 0.891692892322\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(B_clf, x_imp, y_2_new, scoring = \"accuracy\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of accuracy:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.79310345  0.75        0.64444444  0.73684211  0.77142857  0.78947368\n",
      "  0.84375     0.73529412  0.80555556  0.71052632]\n",
      "The average of precision: 0.758041824261\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(B_clf, x_imp, y_2_new, scoring = \"precision\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of precision:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.58536585  0.675       0.725       0.7         0.7         0.75        0.675\n",
      "  0.625       0.725       0.675     ]\n",
      "The average of recall: 0.683536585366\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(B_clf, x_imp, y_2_new, scoring = \"recall\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of recall:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CV results for clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.75124378  0.825       0.84422111  0.88442211  0.85427136  0.83919598\n",
      "  0.87437186  0.87939698  0.72361809  0.83417085]\n",
      "The average of accuracy: 0.83099121228\n"
     ]
    }
   ],
   "source": [
    "G_clf = GaussianNB()\n",
    "answer = cross_val_score(G_clf, x, y_new, scoring = \"accuracy\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of accuracy:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.44        0.54237288  0.57142857  0.71794872  0.62222222  0.6\n",
      "  0.63636364  0.69047619  0.41176471  0.57142857]\n",
      "The average of precision: 0.580400549711\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(G_clf, x, y_new, scoring = \"precision\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of precision:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.80487805  0.8         0.9         0.7         0.7         0.6         0.875\n",
      "  0.725       0.875       0.7       ]\n",
      "The average of recall: 0.767987804878\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(G_clf, x, y_new, scoring = \"recall\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of recall:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CV results for clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.81094527  0.83        0.82        0.83919598  0.85427136  0.85929648\n",
      "  0.84924623  0.81909548  0.83417085  0.85929648]\n",
      "The average of accuracy: 0.837551813795\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(G_clf, x_imp, y_2_new, scoring = \"accuracy\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of accuracy:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.53488372  0.58333333  0.54761905  0.57692308  0.66666667  0.65789474\n",
      "  0.64705882  0.55882353  0.58536585  0.65789474]\n",
      "The average of precision: 0.601646352576\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(G_clf, x_imp, y_2_new, scoring = \"precision\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of precision:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.56097561  0.525       0.575       0.75        0.55        0.625       0.55\n",
      "  0.475       0.6         0.625     ]\n",
      "The average of reacall: 0.583597560976\n"
     ]
    }
   ],
   "source": [
    "answer = cross_val_score(G_clf, x_imp, y_2_new, scoring = \"recall\", cv = 10)\n",
    "print(answer)\n",
    "print(\"The average of reacall:\", sum(answer)/len(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iv. The difference and the enlightenment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the new threshold, all the accuracy of these classifiers are improved, while the precision and recall are relative worse. This shows that clustering (or labling) the output in a better way can improve the performance of prediction since the accuracy is better. Additionally, the precision and recall becoming worse is just showing that the prediction on postive data is worse.(But the total accuracy is increasing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This situation tells us that we should lable the output in a better way which is dividing them into relative seperated and compacted clusters. Under this way, we can get high accuracy using classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
